{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4eb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f77bde",
   "metadata": {},
   "source": [
    "# Считывание всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf04f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadToDf(folder: str):\n",
    "    df = pd.DataFrame(columns=['univ', 'prog', 'name', 'text'])\n",
    "    for file in tqdm(glob.glob('{}/*/*/*.txt'.format(folder))):\n",
    "        splitted = file.split('\\\\')\n",
    "        name = splitted[-1][:-4]\n",
    "        u = splitted[-3]\n",
    "        op = splitted[-2]\n",
    "        \n",
    "        try:\n",
    "            text = open(file, 'r').read()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(file)\n",
    "            text = open(file, 'r', encoding='utf-8').read()\n",
    "        \n",
    "        df = df.append({'univ':u, 'prog':op, 'name':name, 'text':name + ' ' + text.lower()}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a767c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008903a03d644adebc3c672ef8b1d0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3022 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = ReadToDf('files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee36ab",
   "metadata": {},
   "source": [
    "# Лемматизация текста\n",
    "* https://habr.com/ru/post/205360/\n",
    "* https://russianblogs.com/article/9814548532/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0aeea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "a = ord('а')\n",
    "default_stop = set(stopwords.words('russian') + [chr(i) for i in range(a, a + 32)] + [_ for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141278e7",
   "metadata": {},
   "source": [
    "Лемматизацию текста можно проводить с помощью двух популярных библиотек для русского языка: `pymorphy2` и `pymystem3`. Выбор для данной работы -- `pymystem3`. Основное преимущество: простота использования и контекстная лемматизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae57c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "ms = Mystem()\n",
    "\n",
    "regs = [\n",
    "    r'аннотация', r'\\sический\\s', r'\\sопоп\\s',\n",
    "    r'\\sшт\\s', r'\\sдр\\s', r'\\sго\\s', r'\\sита\\s', r'\\sия\\s', r'\\sв?ах\\s',\n",
    "    r'\\sсей\\s', r'\\sтий\\s', r'\\sвать\\s', r'\\sдея\\s',\n",
    "    r'\\ d?\\d*?\\ ', '0302',\n",
    "    r'[·•—“”„№¶…>%=’]',\n",
    "]\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmas = ms.lemmatize(text)\n",
    "    text = ''.join(lemmas).rstrip('\\n')\n",
    "    for reg in regs:\n",
    "        text = re.sub(reg, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33222f",
   "metadata": {},
   "source": [
    "Предыдущая работы была проделана с целью очистки текста так, чтобы фильная обработка включала в себя только удаление лишних слов. Таким образом, были удалены лишние конструкции, такие как, например, \"20 часов\", \"целями дисциплины являются\", \"основные компетенции\" и т. д., удалены знаки пунктуации, кроме дефиса: некоторые важные составные слова могут существенно повлиять на качество модели (SQL-запрос, web-разработка, т. д.).\n",
    "\n",
    "Для начала удалим все стоп-слова: союзы, предлоги и т. д., затем проведем количественный анализ слов, и из каждого текста удалим определенный процент часто- и редковстречаемых слов.\n",
    "\n",
    "Решено было удалить и кодировки компетенций, которые изначально планировалось оставить. Такое решение позволило в три раза уменьшить словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6cb65f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 2882.502287387848 s.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "comp_regs = [\n",
    "    r'ОПК[\\-\\ ]?\\d\\d?',\n",
    "    r'ПК[\\-\\ ]?\\d\\d?',\n",
    "    r'УК[\\-\\ ]?\\d\\d?',\n",
    "    r'ОК[\\-\\ ]?\\d\\d?',\n",
    "    r'ИДЫ[\\-\\ ]?\\d\\d?',\n",
    "    r'ИДК[\\-\\ ]?\\d\\d?',\n",
    "]\n",
    "\n",
    "def process_text(text, f_lemmatizer=lemmatize, wstop=default_stop, counter=None):\n",
    "    if f_lemmatizer is not None:\n",
    "        text = f_lemmatizer(text)\n",
    "    \n",
    "    for reg in comp_regs:\n",
    "        text = re.sub(reg, '', text, flags=re.IGNORECASE)\n",
    "              \n",
    "    text = [word for word in word_tokenize(text) if word not in wstop]\n",
    "    if counter is not None:\n",
    "        counter.update(text)\n",
    "    return ' '.join(text)\n",
    "\n",
    "fd_counter = FreqDist()\n",
    "\n",
    "start = time.time()\n",
    "df.text = df.text.apply(process_text, counter=fd_counter)\n",
    "print('Time spent: {} s.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039b55aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19027"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9566f2",
   "metadata": {},
   "source": [
    "Код выше выполняется около часа, поэтому перепишем результат его работы в json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75055b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsonStr = json.dumps(dict(fd_counter.most_common()), ensure_ascii=False)\n",
    "file = open('JsonCounter.json', 'w')\n",
    "file.write(jsonStr)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209368b0",
   "metadata": {},
   "source": [
    "Переписывание файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "317536c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(folder: str, df):\n",
    "    for row in df.iterrows():\n",
    "        r = row[1]\n",
    "        path = folder + '\\\\' + r['univ'] + '\\\\' + r['prog']\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        filename = path + '\\\\' + r['name'] + '.txt'\n",
    "\n",
    "        file_ = open(filename, 'w', encoding='ansi')\n",
    "        try:\n",
    "            file_.write(r['text'])\n",
    "        except Exception as e:\n",
    "            print('FATAL:', e)\n",
    "            print(row[0], filename)\n",
    "            file_.close() \n",
    "            break\n",
    "        file_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0302f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite('files_lemm', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a563e8",
   "metadata": {},
   "source": [
    "Если посмотреть на получившийся словарь, то среди редковстречаемых слов можно обнаружить множество выбросов: отрывки слов, необычные символы, и т. д. Проблема заключается в том, что такие слова часто встречаются столько же раз, сколько и семантически важные слова, что может существенно испортить качество кластеризации. Данная проблема возникла из-за несовершенства парсинга, а так же опечаток, допущенных в процессе составления документа авторами.\n",
    "\n",
    "Чтобы сгладить углы проблемы, удалим те слова, которые начинаются не с буквы: если лексикографически отсортировать получившийся словарь, то легко понять, что первые слова, стоящие до слов, начинающийхся на английскую `a` являются невалидными. Примеры таких слов: 19гfreeware, 25002900лексическихединиц, 14экзаменаци.\n",
    "\n",
    "Конечно, это не панацея, и опечатки все равно останутся, однако их будет меньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c11b77e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18723"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_dict = {}\n",
    "typo_words = []\n",
    "for item in sorted(fd_counter.items()):\n",
    "    if not str.isalpha(item[0][0]):\n",
    "        typo_words.append(item[0])\n",
    "        continue\n",
    "    corrected_dict[item[0]] = item[1]\n",
    "len(corrected_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e59c257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'система': 10631, 'метод': 8273, 'задача': 7434, 'навык': 6622, 'основной': 6561, 'информационный': 6452, 'решение': 5816, 'дисциплина': 5802, 'деятельность': 5534, 'программный': 4893, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = FreqDist(corrected_dict)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3fd61",
   "metadata": {},
   "source": [
    "### Удаление слов\n",
    "Удалим слова, которые встречаются менее 4 раз и слова, встречающиеся более 2000 раз, а также некоторые контекстные слова и опечатки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f30c1a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12499"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_stop = ['раздел', 'результат', 'освоение', 'применение', 'использование', 'изучение', 'практика',\n",
    "    'представление', 'модуль', 'владеть', 'знать', 'уметь', 'применять', 'понятие', 'формирование',\n",
    "    'создание', 'развитие', 'получать', 'иметь', 'опыт', 'студент', 'изучение', 'структура', 'умение',\n",
    "    'использовать', 'общий', 'организация', 'опк', 'oпк', 'пк', 'ук', 'ок', 'принцип', 'назначение', 'цель',\n",
    "    'способный', 'определение', 'построение', 'вид', 'проект', 'особенность', 'стр', 'стp', 'cтp', 'кoд',\n",
    "    'б1', 'выпускник', 'иной', 'развивать', 'текущий', 'важный', 'ечас', 'позволять',  'направление',\n",
    "    'бакалавр', 'лекция', 'находить', 'понимать', 'иметься', 'обладать', 'тема', 'ых', 'ый', 'подготовка',\n",
    "    'самостоятельно', 'профиль', 'научать', 'специалист', 'иса', 'ита', 'осваивать', 'выпускной',\n",
    "    'общепрофессиональный', 'a', 'разный', 'решать', 'июль', 'ока', 'oка', 'окa', 'квалификационный',\n",
    "    'осуществление', 'первый', 'второй', 'третий', 'четвертый', 'пятый',  'комп', 'тенция', 'граммный',\n",
    "    'отчет', 'весь', 'контрольный', 'овладение', 'самостоятельный', 'зачетный', 'единица',\n",
    "    'давать', 'работать', 'выбирать', 'свой', 'курс', 'формировать','произ', 'водство', 'шение',\n",
    "    'зад', 'ние', 'информ', 'ин', 'ровать', 'ного', 'ре', 'пoмещение', 'помещениe', 'наименование', 'также', \n",
    "]\n",
    "\n",
    "words_most = []\n",
    "words_least = []\n",
    "most = 2000\n",
    "least = 4\n",
    "for w in d.keys():\n",
    "    if d[w] >= most:\n",
    "        words_most.append(w)\n",
    "    elif d[w] <= least:\n",
    "        words_least.append(w)\n",
    "\n",
    "upd_wstop = set(words_most + words_least + typo_words + context_stop)\n",
    "len(upd_wstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a070a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 3.319998025894165 s.\n"
     ]
    }
   ],
   "source": [
    "fd_counter_trunc = FreqDist()\n",
    "df_trunc = df.copy()\n",
    "\n",
    "start = time.time()\n",
    "df_trunc.text = df_trunc.text.apply(process_text, f_lemmatizer=None, wstop=upd_wstop, counter=fd_counter_trunc)\n",
    "print('Time spent: {} s.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1690aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6538"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dict(fd_counter_trunc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab293fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonStr_trunc = json.dumps(dict(fd_counter_trunc.most_common()), ensure_ascii=False)\n",
    "file = open('JsonCounter_trunc.json', 'w')\n",
    "file.write(jsonStr_trunc)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6826d05d",
   "metadata": {},
   "source": [
    "Удалим дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad366a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2559"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trunc.drop_duplicates(subset='text', inplace=True)\n",
    "rewrite('files_lemm', df_trunc)\n",
    "len(df_trunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4abefe",
   "metadata": {},
   "source": [
    "Посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3656d96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число университетов: 12\n",
      "Число направлений: 54\n"
     ]
    }
   ],
   "source": [
    "print('Число университетов: {}'.format(len(df_trunc['univ'].unique())))\n",
    "print('Число направлений: {}'.format(len(df_trunc['prog'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fde859c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['АГТУ', 'АГУ', 'АлтГТУ', 'АлтГУ', 'АмГУ', 'БашГУ', 'БГТУ',\n",
       "       'БГУ Петровского', 'ВолгГТУ', 'ВолГУ', 'ВУиТ', 'ИМСИТ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trunc['univ'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
