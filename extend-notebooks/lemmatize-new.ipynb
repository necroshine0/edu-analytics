{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f6205a",
   "metadata": {},
   "source": [
    "# Лемматизация и очистка от контекстных стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7538c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "UNIVS = ['АлтГУ', 'АлтГТУ', 'ВолГУ', 'ИМСИТ']\n",
    "CURRPATH = os.getcwd()\n",
    "DATAPATH = '\\\\'.join(CURRPATH.split('\\\\')[:-1]) + '\\\\new-data'\n",
    "FILESPATH = DATAPATH + '\\\\new-files'\n",
    "\n",
    "# Документы, которые невозможно адекватно парсить:\n",
    "IGNOREFILES = [\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование история и право 3++\\\\сопоставительная германистика.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование англ нем 3++\\\\культурология.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование англ нем 3++\\\\история немецкого языка.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование изобразительное искусство и информатика\\\\основы проектной деятельности.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование история и право 3++\\\\методика обучения немецкий язык.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование история и право 3++\\\\основы проектной деятельности.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование история и право 3++\\\\практический курс английского языка.txt',\n",
    "    '\\\\ИМСИТ\\\\прикладная информатика\\\\системы управления хранилищами данных.txt',\n",
    "    '\\\\ИМСИТ\\\\прикладная информатика\\\\теория вероятностей и математическая статистика.txt',\n",
    "    '\\\\ИМСИТ\\\\прикладная информатика\\\\физическая культура и спорт общая физическая подготовка.txt',\n",
    "    '\\\\ИМСИТ\\\\реклама и связи с общественностью 3++\\\\практикум технологиии эффективного общения.txt',\n",
    "    '\\\\АлтГУ\\\\юриспруденция общеправовой\\\\конституционное право.txt',\n",
    "    '\\\\АлтГТУ\\\\цифровая экономика\\\\проектирование информационных систем.txt',\n",
    "]\n",
    "\n",
    "# Образовательные направления -- крайне специфичные и сложнокластеризуемые\n",
    "# Для таких направлений нужно много данных\n",
    "IGNOREFOLDERS = [\n",
    "    'гостиничное дело',\n",
    "    'графический дизайн',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f599cb",
   "metadata": {},
   "source": [
    "## Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fefd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_to_df(folder: str, ignorefiles=IGNOREFILES, ignorefolders=IGNOREFOLDERS):\n",
    "    df = pd.DataFrame(columns=['univ', 'prog', 'name', 'text'])\n",
    "    for file in tqdm(glob.glob('{}/*/*/*.txt'.format(folder))):\n",
    "        splitted = file.split('\\\\')\n",
    "        name = splitted[-1][:-4]\n",
    "        u = splitted[-3]\n",
    "        op = splitted[-2]\n",
    "        \n",
    "        path = '\\\\' + u + '\\\\' + op + '\\\\' + splitted[-1]\n",
    "        if  path in ignorefiles or \\\n",
    "                op in ignorefolders or \\\n",
    "                'практик' in splitted[-1] or \\\n",
    "                'введение в специальность' in splitted[-1] or \\\n",
    "                'введение в професси' in splitted[-1]:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            text = open(file, 'r').read()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(file)\n",
    "            text = open(file, 'r', encoding='utf-8').read()\n",
    "        \n",
    "        df = df.append({'univ':u, 'prog':op, 'name':name, 'text':text.lower()}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2ed9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0eb365b9443468bac98a1a6f1a19df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3009"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_to_df(FILESPATH)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0fbf23",
   "metadata": {},
   "source": [
    "## Удаление дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348b8e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2464"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset='text', inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41e12d",
   "metadata": {},
   "source": [
    "## Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2825b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "ms = Mystem()\n",
    "\n",
    "a = ord('а')\n",
    "DEFAULT_STOP = set(stopwords.words('russian') + [chr(i) for i in range(a, a + 32)] + [_ for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0013f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text, regs=None):\n",
    "    lemmas = ms.lemmatize(text)\n",
    "    text = ''.join(lemmas).rstrip('\\n')\n",
    "    if regs is not None:\n",
    "        for reg in regs:\n",
    "            text = re.sub(reg, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_text(text, f_lemmatizer=lemmatize, wstop=DEFAULT_STOP,\n",
    "                 lemm_regs=None, other_regs=None, counter=None):\n",
    "    \n",
    "    if f_lemmatizer is not None:\n",
    "        text = f_lemmatizer(text, lemm_regs)\n",
    "    \n",
    "    if other_regs is not None:\n",
    "        for reg in other_regs:\n",
    "            text = re.sub(reg, '', text, flags=re.IGNORECASE)\n",
    "              \n",
    "    text = [word for word in word_tokenize(text) if word not in wstop and str.isalpha(word[0])]\n",
    "    if counter is not None:\n",
    "        counter.update(text)\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bed5b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 2226.985454559326 s.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "fd_counter = FreqDist()\n",
    "\n",
    "start = time.time()\n",
    "df.text = df.text.apply(process_text, counter=fd_counter)\n",
    "print('Time spent: {} s.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce694ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18224"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33be1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsonStr = json.dumps(dict(fd_counter.most_common()), ensure_ascii=False)\n",
    "file = open('JsonCounter.json', 'w')\n",
    "file.write(jsonStr)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0949c1e",
   "metadata": {},
   "source": [
    "Установим пороги на число вхождений: верхний 2100, нижний -- 1, так как среди таких слов много опечаток по вине составителей документов. В этом случае некоторые документы могут потерять суть, но этим стоит пожертвовать в угоду других документов. Отдельно вернем слова иностранных языков и некоторые другие термины. Удалим слова, длина которых не более двух."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53487679",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = open('saved.txt', 'r', encoding='utf-16')\n",
    "saved_words = file_.read().replace('\\{', '').replace('\\}', '').replace(': 1', '').replace('\\\"', '').split(',')\n",
    "file_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12a4227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = fd_counter\n",
    "words_most = []\n",
    "words_least = []\n",
    "other_words = []\n",
    "most = 400\n",
    "least = 1\n",
    "for w in d.keys():\n",
    "    if d[w] >= most:\n",
    "        words_most += [w]\n",
    "    elif d[w] <= least:\n",
    "        words_least += [w]\n",
    "    elif len(w) < 3:\n",
    "        other_words += [w]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032f6d9",
   "metadata": {},
   "source": [
    "Также удалим некоторые контекстные слова, которые в теории могут мешать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14e67b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_stop = [\n",
    "    'определять', 'выявлять', 'актуальный', 'уп', 'опоп', 'пример', 'понимание',\n",
    "    'понимать', 'знать', 'знание', 'учитывать', 'дв', 'владение', 'описание', 'проводить',\n",
    "    'весь', 'вся', 'все', 'проектный', 'который', 'особый', 'ознакомление', 'the', 'опк',\n",
    "    'специалист', 'семестр', 'первый', 'второй', 'третий', 'четвертый', 'пятый', 'знакомство',\n",
    "    'готовность', 'модуль', 'задание', 'др', 'иметься', 'единица', 'соответствующий', 'часы',\n",
    "    'работник', 'задание', 'обосновывать', 'учитывать', 'формат', 'наиболее', 'наименее',\n",
    "    'формулировать', 'заключение', 'научать', 'зачет', 'познакомить', 'a', 'выделять',\n",
    "    'участвовать', 'экзамен', 'оформлять', 'соблюдать', 'делать', 'обоснованный', 'лекция',\n",
    "    'урок', 'содержаться', 'содержание', 'каждый', 'текущий', 'это', 'существующий', 'учащийся',\n",
    "    'выпускной', 'учебник', 'интернет-ресурс', 'ожидать', 'заочный', 'очный', 'го', 'обзор',\n",
    "    'раздел', 'результат', 'освоение', 'применение', 'использование', 'изучение', 'практика',\n",
    "    'представление', 'владеть', 'знать', 'уметь', 'применять', 'понятие', 'формирование',\n",
    "    'создание', 'развитие', 'получать', 'иметь', 'опыт', 'студент', 'изучение', 'структура', 'умение',\n",
    "    'использовать', 'общий', 'организация', 'опк', 'oпк', 'ок', 'принцип', 'назначение', 'цель',\n",
    "    'способный', 'определение', 'построение', 'вид', 'проект', 'особенность', 'стр', 'стp', 'cтp',\n",
    "    'б1', 'выпускник', 'иной', 'развивать', 'текущий', 'важный', 'позволять',  'направление',\n",
    "    'бакалавр', 'находить', 'обладать', 'тема', 'ых', 'ый', 'подготовка', 'оформление', 'сосредоточивать',\n",
    "    'самостоятельно', 'профиль', 'специалист', 'осваивать', 'общепрофессиональный', 'a', 'разный',\n",
    "    'решать', 'июль', 'ока', 'oка', 'окa', 'квалификационный', 'осуществление', 'отчет', 'весь',\n",
    "    'контрольный', 'овладение', 'самостоятельный', 'давать', 'работать', 'выбирать', 'свой', 'курс',\n",
    "    'формировать', 'помещениe', 'наименование', 'также', 'сформированность', 'обладать', 'небольшой',\n",
    "    'большой', 'малый', 'тео-рий', 'интер-нет', 'пять', 'организа-ции', 'сист', 'ми', 'ч2', 'ч1', 'ч3',\n",
    "    'соци-альный', 'подготовка', 'пожготовка', 'весьма', 'куультура', 'политическои', 'вспомогатель-ных',\n",
    "    'элька-тромагнетизм', 'вещий-ство', 'воспа', 'эксплуотация', 'социаль-ного', 'подго-товка',\n",
    "    'кон-цепция', 'особенностмевать', 'прочее', 'гражданин-ского', 'требовать', 'воспринимать', 'включая',\n",
    "    'опираться', 'ук', 'методология', 'методологический', 'инструмент', 'составлять', 'влияние', 'публич-ную',\n",
    "    'полити-ческий', 'поставлять-ных', 'исследовый-нию', 'транс-формация', 'формулиро-вания', 'самостоятельно-го',\n",
    "    'социологич-ские', 'иссле-дование', 'норматив-ной', 'функ-циональный', 'расти-сийский', 'лредоставление',\n",
    "    'характа-ризовать', 'публич-ную', 'пройка-тирование', 'эко-номический', 'эконо-метрический', \n",
    "    'экономет-рический', 'эконометриче-ского', 'изученииособенность', 'знаия',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42bafcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8021, False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_wstop = set(words_most + words_least + other_words + context_stop) - set(saved_words)\n",
    "len(upd_wstop), set(saved_words) in upd_wstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e91c21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_counter_trunc = FreqDist()\n",
    "df_trunc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5139c8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 2.8519551753997803 s.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_trunc.text = df_trunc.text.apply(process_text, f_lemmatizer=None, wstop=upd_wstop, counter=fd_counter_trunc)\n",
    "print('Time spent: {} s.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dea8483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10217"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dict(fd_counter_trunc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf140f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonStr_trunc = json.dumps(dict(fd_counter_trunc.most_common()), ensure_ascii=False)\n",
    "file = open('JsonCounter_trunc.json', 'w')\n",
    "file.write(jsonStr_trunc)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc08ba5",
   "metadata": {},
   "source": [
    "## Запись"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49cdaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(folder: str, df):\n",
    "    for row in tqdm(df.iterrows()):\n",
    "        r = row[1]\n",
    "        path = folder + '\\\\' + r['univ'] + '\\\\' + r['prog']\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        filename = path + '\\\\' + r['name'] + '.txt'\n",
    "\n",
    "        file_ = open(filename, 'w', encoding='ansi')\n",
    "        try:\n",
    "            file_.write(r['text'])\n",
    "        except Exception as e:\n",
    "            print('FATAL:', e)\n",
    "            print(row[0], filename)\n",
    "            file_.close() \n",
    "            break\n",
    "        file_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1279e4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8bea8651ae499aaa8013832460c591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewrite(DATAPATH + '\\\\new-files-lemm', df_trunc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
