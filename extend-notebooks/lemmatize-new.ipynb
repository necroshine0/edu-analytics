{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f6205a",
   "metadata": {},
   "source": [
    "# Лемматизация и очистка от контекстных стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7538c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "UNIVS = ['АлтГУ', 'АлтГТУ', 'ВолГУ', 'ИМСИТ']\n",
    "CURRPATH = os.getcwd()\n",
    "DATAPATH = '\\\\'.join(CURRPATH.split('\\\\')[:-1]) + '\\\\new-data'\n",
    "FILESPATH = DATAPATH + '\\\\new-files'\n",
    "\n",
    "# Документы, которые невозможно адекватно парсить:\n",
    "IGNOREFILES = [\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование история и право 3++\\\\сопоставительная германистика.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование англ нем 3++\\\\культурология.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование англ нем 3++\\\\история немецкого языка.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование изобразительное искусство и информатика\\\\основы проектной деятельности.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование история и право 3++\\\\методика обучения немецкий язык.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование история и право 3++\\\\основы проектной деятельности.txt',\n",
    "    '\\\\ИМСИТ\\\\педагогическое образование история и право 3++\\\\практический курс английского языка.txt',\n",
    "    '\\\\ИМСИТ\\\\прикладная информатика\\\\системы управления хранилищами данных.txt',\n",
    "    '\\\\ИМСИТ\\\\прикладная информатика\\\\теория вероятностей и математическая статистика.txt',\n",
    "    '\\\\ИМСИТ\\\\прикладная информатика\\\\физическая культура и спорт общая физическая подготовка.txt',\n",
    "    '\\\\ИМСИТ\\\\реклама и связи с общественностью 3++\\\\практикум технологиии эффективного общения.txt',\n",
    "    '\\\\АлтГУ\\\\юриспруденция общеправовой\\\\конституционное право.txt',\n",
    "    '\\\\АлтГТУ\\\\цифровая экономика\\\\проектирование информационных систем.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f599cb",
   "metadata": {},
   "source": [
    "## Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fefd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_to_df(folder: str, ignore=IGNOREFILES):\n",
    "    df = pd.DataFrame(columns=['univ', 'prog', 'name', 'text'])\n",
    "    for file in tqdm(glob.glob('{}/*/*/*.txt'.format(folder))):\n",
    "        splitted = file.split('\\\\')\n",
    "        name = splitted[-1][:-4]\n",
    "        u = splitted[-3]\n",
    "        op = splitted[-2]\n",
    "        if '\\\\' + u + '\\\\' + op + '\\\\' + splitted[-1] in ignore:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            text = open(file, 'r').read()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(file)\n",
    "            text = open(file, 'r', encoding='utf-8').read()\n",
    "        \n",
    "        df = df.append({'univ':u, 'prog':op, 'name':name, 'text':text.lower()}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2ed9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe29d8347f2640b99bb0aa1629724c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3663"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_to_df(FILESPATH)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0fbf23",
   "metadata": {},
   "source": [
    "## Удаление дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348b8e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset='text', inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41e12d",
   "metadata": {},
   "source": [
    "## Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2825b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "ms = Mystem()\n",
    "\n",
    "a = ord('а')\n",
    "DEFAULT_STOP = set(stopwords.words('russian') + [chr(i) for i in range(a, a + 32)] + [_ for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0013f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text, regs=None):\n",
    "    lemmas = ms.lemmatize(text)\n",
    "    text = ''.join(lemmas).rstrip('\\n')\n",
    "    if regs is not None:\n",
    "        for reg in regs:\n",
    "            text = re.sub(reg, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_text(text, f_lemmatizer=lemmatize, wstop=DEFAULT_STOP,\n",
    "                 lemm_regs=None, other_regs=None, counter=None):\n",
    "    \n",
    "    if f_lemmatizer is not None:\n",
    "        text = f_lemmatizer(text, lemm_regs)\n",
    "    \n",
    "    if other_regs is not None:\n",
    "        for reg in other_regs:\n",
    "            text = re.sub(reg, '', text, flags=re.IGNORECASE)\n",
    "              \n",
    "    text = [word for word in word_tokenize(text) if word not in wstop]\n",
    "    if counter is not None:\n",
    "        counter.update(text)\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bed5b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 2802.084702014923 s.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "fd_counter = FreqDist()\n",
    "\n",
    "start = time.time()\n",
    "df.text = df.text.apply(process_text, counter=fd_counter)\n",
    "print('Time spent: {} s.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce694ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33be1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsonStr = json.dumps(dict(fd_counter.most_common()), ensure_ascii=False)\n",
    "file = open('JsonCounter.json', 'w')\n",
    "file.write(jsonStr)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54f71b",
   "metadata": {},
   "source": [
    "Еще небольшая очистка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "470615b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_dict = {}\n",
    "typo_words = []\n",
    "for item in sorted(fd_counter.items()):\n",
    "    if not str.isalpha(item[0][0]):\n",
    "        typo_words.append(item[0])\n",
    "        continue\n",
    "    corrected_dict[item[0]] = item[1]\n",
    "len(corrected_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1015291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'дисциплина': 13067, 'навык': 12679, 'деятельность': 11297, 'метод': 8814, 'основной': 8715, 'знание': 7945, 'система': 7933, 'профессиональный': 7069, 'основа': 6548, 'анализ': 6257, ...})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = FreqDist(corrected_dict)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0949c1e",
   "metadata": {},
   "source": [
    "Установим пороги на число вхождений: верхний 500, нижний -- отсутствует, так как есть некоторые слова, которые встречаются лишь однажды (например, немецкие)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a4227f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9589"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_most = []\n",
    "words_least = []\n",
    "most = 500\n",
    "least = 1\n",
    "for w in d.keys():\n",
    "    if d[w] >= most:\n",
    "        words_most.append(w)\n",
    "    elif d[w] <= least:\n",
    "        words_least.append(w)\n",
    "\n",
    "upd_wstop = set(words_most + words_least + typo_words)\n",
    "len(upd_wstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91c21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_counter_trunc = FreqDist()\n",
    "df_trunc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5139c8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 3.74792742729187 s.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_trunc.text = df_trunc.text.apply(process_text, f_lemmatizer=None, wstop=upd_wstop, counter=fd_counter_trunc)\n",
    "print('Time spent: {} s.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea8483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12555"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dict(fd_counter_trunc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf140f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonStr_trunc = json.dumps(dict(fd_counter_trunc.most_common()), ensure_ascii=False)\n",
    "file = open('JsonCounter_trunc.json', 'w')\n",
    "file.write(jsonStr_trunc)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc08ba5",
   "metadata": {},
   "source": [
    "## Запись"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49cdaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(folder: str, df):\n",
    "    for row in df.iterrows():\n",
    "        r = row[1]\n",
    "        path = folder + '\\\\' + r['univ'] + '\\\\' + r['prog']\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        filename = path + '\\\\' + r['name'] + '.txt'\n",
    "\n",
    "        file_ = open(filename, 'w', encoding='ansi')\n",
    "        try:\n",
    "            file_.write(r['text'])\n",
    "        except Exception as e:\n",
    "            print('FATAL:', e)\n",
    "            print(row[0], filename)\n",
    "            file_.close() \n",
    "            break\n",
    "        file_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1279e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite(DATAPATH + '\\\\new-files-lemm', df_trunc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
